\documentclass{article}

\usepackage{arxiv}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{graphicx}
\usepackage[style=ieee,backend=bibtex]{biblatex}

\addbibresource{references.bib}


\title{bevy\_zeroverse: Pre-training Reconstruction Models with Multi-scale Synthesized Data \\ \large{\textbf{Work in Progress}}}

\author{ \href{https://orcid.org/0009-0009-8476-3358}{\hspace{1mm}Mitchell Mosure} \\
    Organization Name\\
    \texttt{mitchell@mosure.me} \\
}

% Uncomment to remove the date
%\date{}

% Uncomment to override the `A preprint` in the header
%\renewcommand{\headeright}{Technical Report}
%\renewcommand{\undertitle}{Technical Report}
\renewcommand{\shorttitle}{bevy\_zeroverse: Pre-training Reconstruction Models}

\hypersetup{
    pdftitle={bevy\_zeroverse: Pre-training Reconstruction Models with Multi-scale Synthesized Data},
    pdfsubject={cs.CV, cs.LG},
    pdfauthor={Mitchell Mosure},
    pdfkeywords={synthetic data, pre-training, reconstruction models},
}

\begin{document}
\maketitle

\begin{abstract}
We present bevy\_zeroverse, a procedural synthetic dataset generator for pre-training reconstruction models. bevy\_zeroverse synthesizes datasets from primitive shapes with random materials, augmentations (e.g., normal deformation, boolean manifold operations, thin structures, hierarchical transforms), and multi-scale composition (e.g., object, room, and environment scales). Unlike previous works (e.g., Objaverse, Zeroverse) that target the object-scale 3D domain, bevy\_zeroverse extends into the multi-scale 4D domain, enabling the training of models that can generalize to larger, more complex, dynamic scenes. We demonstrate that pre-training on bevy\_zeroverse improves the performance of a reconstruction model on real-world data, achieving high-quality, sparse-view reconstructions. Additionally, we analyze the impact of synthetic data parameters on model training and performance. Our work highlights the potential of synthetic data for pre-training reconstruction models and emphasizes the importance of multi-scale, multi-domain data generation for training models that can generalize to complex, real-world scenes.
\end{abstract}

\section{Introduction}
We present bevy\_zeroverse, a procedural synthetic dataset generator for pre-training reconstruction models. bevy\_zeroverse synthesizes datasets from primitive shapes with random materials, augmentations (e.g., normal deformation, boolean manifold operations, thin structures, hierarchical transforms), and multi-scale composition (e.g., object, room, and environment scales). Unlike previous works (e.g., Objaverse, Zeroverse) that target the object-scale 3D domain, bevy\_zeroverse extends into the multi-scale 4D domain, enabling the training of models that can generalize to larger, more complex, dynamic scenes.

\section{Methodology}
\subsection{Dataset Generation}
bevy\_zeroverse synthesizes datasets from primitive shapes with random materials and augmentations. These augmentations include normal deformation, boolean manifold operations, thin structures, and hierarchical transforms. The generated datasets span multiple scales, including object, room, and environment scales.

\subsection{Training Process}
The datasets generated by bevy\_zeroverse are used to pre-train reconstruction models. We demonstrate that pre-training on these synthetic datasets improves the performance of reconstruction models on real-world data. Our experiments show high-quality, sparse-view reconstructions.

\section{Results}
We analyze the impact of synthetic data parameters on model training and performance. Our results highlight the potential of synthetic data for pre-training reconstruction models and emphasize the importance of multi-scale, multi-domain data generation for training models that can generalize to complex, real-world scenes.

\section{Conclusion}
Our work demonstrates the effectiveness of bevy\_zeroverse in generating synthetic datasets for pre-training reconstruction models. The multi-scale, multi-domain nature of the generated data enables models to generalize better to complex, dynamic scenes. This highlights the importance of synthetic data in advancing the field of reconstruction models.

% TODO: debug tectonic references.bib sourcing
% \printbibliography

\begin{thebibliography}{1}

    \bibitem{tang2024lgm}
    Jiaxiang Tang, Zhaoxi Chen, Xiaokang Chen, Tengfei Wang, Gang Zeng, and Ziwei Liu.
    \newblock LGM: Large Multi-View Gaussian Model for High-Resolution 3D Content Creation.
    \newblock {\em arXiv preprint arXiv:2402.05054}, 2024.

    \bibitem{xie2024lrmzero}
    Desai Xie, Sai Bi, Zhixin Shu, Kai Zhang, Zexiang Xu, Yi Zhou, SÃ¶ren Pirk, Arie Kaufman, Xin Sun, and Hao Tan.
    \newblock LRM-Zero: Training Large Reconstruction Models with Synthesized Data.
    \newblock {\em arXiv preprint arXiv:2406.09371}, 2024.

    \bibitem{chen2024mvsplat}
    Yuedong Chen, Haofei Xu, Chuanxia Zheng, Bohan Zhuang, Marc Pollefeys, Andreas Geiger, Tat-Jen Cham, and Jianfei Cai.
    \newblock MVSplat: Efficient 3D Gaussian Splatting from Sparse Multi-View Images.
    \newblock {\em arXiv preprint arXiv:2403.14627}, 2024.

    \bibitem{zhang2024geolrm}
    Chubin Zhang, Hongliang Song, Yi Wei, Yu Chen, Jiwen Lu, and Yansong Tang.
    \newblock GeoLRM: Geometry-Aware Large Reconstruction Model for High-Quality 3D Gaussian Generation.
    \newblock {\em arXiv preprint arXiv:2406.15333}, 2024.

\end{thebibliography}

\end{document}
